{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "Self-Retrieval-Augmented Generation (Self-RAG) is an advanced variant of Retrieval-Augmented Generation (RAG) that enhances retrieval efficiency by allowing the model to refine its own queries iteratively. Unlike traditional RAG, where user queries are directly used for retrieval, Self-RAG enables an LLM to autonomously generate and improve search queries, leading to better information retrieval and response generation."
      ],
      "metadata": {
        "id": "rZ33e3-3q4_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Concepts of Self-RAG**\n",
        "Self-RAG introduces query self-refinement and iterative retrieval, making it more dynamic and capable of handling complex queries. It consists of the following key components:\n",
        "\n",
        "1. **Query Expansion & Refinement**\n",
        "\n",
        "  * The model rephrases or expands the user query to improve retrieval performance.\n",
        "  * This ensures that retrieved documents are more relevant to the intent of the query.\n",
        "2. **Self-Iterative Retrieval**\n",
        "\n",
        "  * Instead of retrieving documents only once, the model refines its query iteratively to get the most accurate results.\n",
        "3. **Feedback Loop**\n",
        "\n",
        "  * The retrieved results influence further query modifications.\n",
        "  * The system uses a feedback loop to adjust and refine the generated text.\n",
        "4. **Multi-Step Reasoning**\n",
        "\n",
        "  * Instead of generating an answer from a single retrieval pass, the model retrieves, processes, and refines information in multiple steps."
      ],
      "metadata": {
        "id": "eLjyWLXYrLK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applications of Self-RAG**\n",
        "Self-RAG is beneficial in various AI-driven applications, including:\n",
        "\n",
        "1. Legal and Research Document Analysis\n",
        "\n",
        "  * Helps refine complex legal queries for better case law retrieval.\n",
        "2. Medical Q&A Systems\n",
        "\n",
        "  * Improves retrieval of patient-specific or disease-related information.\n",
        "3. Enterprise Knowledge Management\n",
        "\n",
        "  * Enhances internal company knowledge retrieval by refining queries based on contextual clues.\n",
        "4. Customer Support Chatbots\n",
        "\n",
        "  * Enables intelligent, multi-step query resolution.\n",
        "5. Code Search and Documentation Retrieval\n",
        "\n",
        "  * Enhances search in large repositories like GitHub or API documentation."
      ],
      "metadata": {
        "id": "wEBNXT5orpaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of Self-RAG in GenAI**"
      ],
      "metadata": {
        "id": "33LsTpcWsI4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-openai langchain-community faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxjRyZfkq_4W",
        "outputId": "ec257fc5-7681-420b-e666-1fbeb64ea809"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from typing import List, Optional, Dict\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "Gl_5OxD6sZon"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "\n",
        "openai_api= userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "5OZ2TF9_sqTv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize components\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0,openai_api_key=openai_api)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\",openai_api_key=openai_api)"
      ],
      "metadata": {
        "id": "WcZzvVb2s0Qz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    Document(page_content=\"The French Revolution began in 1789 with the storming of the Bastille.\"),\n",
        "    Document(page_content=\"Louis XVI was executed in 1793 during the Reign of Terror.\"),\n",
        "    Document(page_content=\"The Revolution led to the rise of Napoleon Bonaparte in 1799.\")\n",
        "]"
      ],
      "metadata": {
        "id": "I7G2dIdbtE0Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhof_W4qta3h",
        "outputId": "b7ea1a6c-ea1a-4ba9-9ec4-c137d9cbbfdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize hybrid retriever (BM25 + FAISS)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Sparse retriever\n",
        "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "# Dense retriever\n",
        "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
        "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "eUx7u_cOtJhc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define Self-RAG components\n",
        "class SelfRAGProcessor:\n",
        "    def __init__(self):\n",
        "        self.retrieval_triggers = [\"[Retrieve]\", \"[Verify]\", \"[Expand]\"]\n",
        "\n",
        "    def _detect_retrieval_need(self, text: str) -> bool:\n",
        "        return any(trigger in text for trigger in self.retrieval_triggers)\n",
        "\n",
        "    def _hybrid_retrieve(self, query: str) -> List[Document]:\n",
        "        # Combine BM25 and FAISS results\n",
        "        bm25_docs = bm25_retriever.invoke(query)\n",
        "        faiss_docs = faiss_retriever.invoke(query)\n",
        "        return self._merge_docs(bm25_docs + faiss_docs)\n",
        "\n",
        "    def _merge_docs(self, docs: List[Document]) -> List[Document]:\n",
        "        # Remove duplicates while preserving order\n",
        "        seen = set()\n",
        "        return [doc for doc in docs if not (doc.page_content in seen or seen.add(doc.page_content))]"
      ],
      "metadata": {
        "id": "aSiQhfRztNwz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create Self-RAG chain\n",
        "self_rag_processor = SelfRAGProcessor()\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a Self-RAG assistant. Use these triggers when needed:\n",
        "     [Retrieve] - When needing factual verification or additional context\n",
        "     [Verify] - When confirming specific facts\n",
        "     [Expand] - When needing broader perspective\n",
        "\n",
        "     Current Context: {context}\"\"\"),\n",
        "    (\"human\", \"{query}\")\n",
        "])\n",
        "\n",
        "def retrieval_wrapper(state: Dict) -> Dict:\n",
        "    query = state[\"query\"]\n",
        "    context = state.get(\"context\", \"\")\n",
        "\n",
        "    # Generate initial response\n",
        "    generation_chain = prompt | llm | StrOutputParser()\n",
        "    response = generation_chain.invoke({\"query\": query, \"context\": context})\n",
        "\n",
        "    # Check if retrieval needed\n",
        "    if self_rag_processor._detect_retrieval_need(response):\n",
        "        retrieved_docs = self_rag_processor._hybrid_retrieve(query)\n",
        "        new_context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "        return {\"query\": query, \"response\": response, \"context\": new_context}\n",
        "\n",
        "    return {\"query\": query, \"response\": response, \"context\": context}\n",
        "\n",
        "self_rag_chain = RunnablePassthrough.assign(\n",
        "    context=lambda x: x.get(\"context\", \"\")\n",
        ") | RunnableLambda(retrieval_wrapper)\n",
        "\n",
        "# 4. Iterative generation with retrieval\n",
        "def full_self_rag(query: str, max_iter=3) -> str:\n",
        "    state = {\"query\": query, \"context\": \"\"}\n",
        "    for _ in range(max_iter):\n",
        "        state = self_rag_chain.invoke(state)\n",
        "        if not self_rag_processor._detect_retrieval_need(state[\"response\"]):\n",
        "            break\n",
        "    return state[\"response\"]"
      ],
      "metadata": {
        "id": "SMtdIAWmtiBD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Test the implementation\n",
        "query = \"Explain the causes of the French Revolution and its consequences\"\n",
        "result = full_self_rag(query)\n",
        "print(\"Self-RAG Output:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOm9LDvGtpF9",
        "outputId": "ae429fe9-3779-4c54-dac2-a4eea6c52769"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-RAG Output:\n",
            " The French Revolution, which took place from 1789 to 1799, was a period of significant social and political upheaval in France. There were several causes of the French Revolution, including:\n",
            "\n",
            "1. **Social Inequality**: The French society was divided into three estates, with the clergy and nobility enjoying privileges and exemptions from taxes, while the common people faced heavy taxation and economic hardship.\n",
            "\n",
            "2. **Financial Crisis**: France was facing a severe financial crisis due to extravagant spending by the monarchy, costly wars, and a regressive tax system that burdened the common people.\n",
            "\n",
            "3. **Enlightenment Ideas**: The ideas of the Enlightenment, which emphasized individual rights, equality, and popular sovereignty, inspired many French people to question the existing social and political order.\n",
            "\n",
            "4. **Weak Leadership**: King Louis XVI's indecisiveness and inability to address the country's problems effectively weakened the monarchy's authority and legitimacy.\n",
            "\n",
            "The consequences of the French Revolution were profound and far-reaching:\n",
            "\n",
            "1. **End of Monarchy**: The French Revolution led to the abolition of the monarchy and the establishment of a republic in France.\n",
            "\n",
            "2. **Reign of Terror**: The radical phase of the revolution, known as the Reign of Terror, saw the rise of the Jacobins and the execution of thousands of perceived enemies of the revolution, including King Louis XVI and Queen Marie Antoinette.\n",
            "\n",
            "3. **Napoleonic Era**: The French Revolution paved the way for Napoleon Bonaparte to rise to power and establish himself as Emperor of France, leading to a period of military conquests and political instability in Europe.\n",
            "\n",
            "4. **Spread of Revolutionary Ideas**: The French Revolution inspired revolutionary movements in other countries and contributed to the spread of democratic ideals and nationalism across Europe.\n",
            "\n",
            "5. **Legacy of the Revolution**: The French Revolution had a lasting impact on French society and politics, leading to the abolition of feudal privileges, the codification of laws, and the rise of modern nationalism.\n",
            "\n",
            "Overall, the French Revolution was a watershed moment in European history that marked the transition from the old order to a new era of political and social change.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS6IFKCRttxv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}