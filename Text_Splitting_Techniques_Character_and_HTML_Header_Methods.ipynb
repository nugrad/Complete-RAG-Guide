{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1Ô∏è‚É£ Why is Text Splitting Important?**\n",
        "LLMs and retrieval models cannot process long documents directly, so we must split them into manageable chunks for:\n",
        "\n",
        "‚úÖ Efficient Retrieval ‚Äì Ensures relevant text is retrieved accurately.\n",
        "\n",
        "‚úÖ Reduced Token Overhead ‚Äì Prevents exceeding LLM token limits.\n",
        "\n",
        "‚úÖ Improved Generation Quality ‚Äì Keeps responses contextually relevant.\n",
        "\n",
        "‚úÖ Better Indexing ‚Äì Enhances searchability in vector databases."
      ],
      "metadata": {
        "id": "U2c_6qz73WkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2Ô∏è‚É£ Overview of Text Splitting Techniques**\n",
        "**We explore two main approaches:**\n",
        "\n",
        "1Ô∏è‚É£ Character-Based Splitting ‚Äì Splitting based on fixed character length.\n",
        "\n",
        "2Ô∏è‚É£ HTML Header Splitting ‚Äì Splitting documents based on structured HTML headings (h1,h2 tags  etc.)."
      ],
      "metadata": {
        "id": "ckno3O_Z3egy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3Ô∏è‚É£ Character-Based Text Splitting**\n",
        "**üîπ Concept**\n",
        "\n",
        "This method splits text into fixed-length chunks while maintaining overlapping contexts for continuity.\n",
        "\n",
        "**üîπ Applications**\n",
        "\n",
        "üìå Handling Long Texts for LLMs ‚Üí Splitting large documents for GPT, BERT, etc.\n",
        "\n",
        "üìå Retrieval-Based AI (RAG) ‚Üí Preparing text for semantic search in vector databases (FAISS, Pinecone).\n",
        "\n",
        "üìå Summarization Pipelines ‚Üí Processing large text blocks before summarization."
      ],
      "metadata": {
        "id": "M4nVhz8E3-Dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e7qKbGMl23lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3770dd6c-a556-4e1e-e66b-51df419524d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Retrieval-Augmented Generation (RAG) models improve AI by retrieving external information.\n",
            "Chunk 2: They enhance response accuracy and reduce hallucinations. RAG is widely used in various AI applications.\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"Retrieval-Augmented Generation (RAG) models improve AI by retrieving external information.\n",
        "They enhance response accuracy and reduce hallucinations. RAG is widely used in various AI applications.\"\"\"\n",
        "\n",
        "# Adjusted parameters\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=120,\n",
        "    chunk_overlap=20,\n",
        "    separators=[\"\\n\", \" \", \"\"],  # Prioritize spaces & newlines\n",
        ")\n",
        "\n",
        "# Perform splitting\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "# Display results\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üìå Why Use Overlap?**\n",
        "\n",
        "Chunk **overlap** (e.g., 10 characters) helps **preserve context across** consecutive chunks, avoiding **loss of meaning** in retrieval and generation."
      ],
      "metadata": {
        "id": "YrtYoZJZ4XxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4Ô∏è‚É£ HTML Header-Based Text Splitting**\n",
        "**üîπ Concept**\n",
        "\n",
        "HTML documents contain structured content using headings (h1,h2,h3). Splitting by headers ensures logical separation of content while maintaining semantic structure.\n",
        "\n",
        "**üîπ Applications**\n",
        "\n",
        "üìå Processing Web Documents ‚Üí Extracting structured data from HTML pages.\n",
        "\n",
        "üìå Summarization of Articles & Reports ‚Üí Separating sections for better analysis.\n",
        "\n",
        "üìå Chunking Knowledge Bases ‚Üí Preparing structured documents for vector search."
      ],
      "metadata": {
        "id": "-_4u0Jzb4sh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey1568mL4NWS",
        "outputId": "bb640e5a-cddf-4874-afd2-06428a51ec1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Sample HTML text\n",
        "html_text = \"\"\"\n",
        "<h1>Introduction to RAG</h1>\n",
        "<p>Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving external knowledge.</p>\n",
        "<h2>Benefits of RAG</h2>\n",
        "<p>RAG improves accuracy and reduces hallucinations.</p>\n",
        "<h2>Applications</h2>\n",
        "<p>Used in chatbots, search engines, and enterprise AI.</p>\n",
        "\"\"\"\n",
        "\n",
        "# Parse HTML\n",
        "soup = BeautifulSoup(html_text, \"html.parser\")\n",
        "\n",
        "# Extract chunks based on headers\n",
        "chunks = []\n",
        "for header in soup.find_all([\"h1\", \"h2\", \"h3\"]):\n",
        "    section = header.get_text()  # Header text\n",
        "    content = header.find_next_sibling(\"p\")  # Paragraph following the header\n",
        "    if content:\n",
        "        chunks.append(f\"{section}\\n{content.get_text()}\")\n",
        "\n",
        "# Display results\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijwyw35-5Bzx",
        "outputId": "29770f99-d694-46a7-f023-94bff54fcb5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "Introduction to RAG\n",
            "Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving external knowledge.\n",
            "\n",
            "Chunk 2:\n",
            "Benefits of RAG\n",
            "RAG improves accuracy and reduces hallucinations.\n",
            "\n",
            "Chunk 3:\n",
            "Applications\n",
            "Used in chatbots, search engines, and enterprise AI.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5Ô∏è‚É£ Combining Both Approaches for Hybrid Splitting**\n",
        "* **For complex documents, we can first split by HTML headers, then apply character-based chunking within each section.**"
      ],
      "metadata": {
        "id": "zqYRd25q5zRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Example sections from HTML splitting\n",
        "sections = [\n",
        "    \"Introduction to RAG\\nRetrieval-Augmented Generation (RAG) enhances LLMs by retrieving external knowledge.\",\n",
        "    \"Benefits of RAG\\nRAG improves accuracy and reduces hallucinations.\",\n",
        "    \"Applications\\nUsed in chatbots, search engines, and enterprise AI.\"\n",
        "]\n",
        "\n",
        "# Apply character splitting within each section\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=25)\n",
        "\n",
        "# Process each section separately\n",
        "final_chunks = []\n",
        "for section in sections:\n",
        "    final_chunks.extend(splitter.split_text(section))\n",
        "\n",
        "# Display results\n",
        "for i, chunk in enumerate(final_chunks):\n",
        "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvNsLCJF5Gf8",
        "outputId": "9fee0333-554a-4366-828d-1802835a080e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "Introduction to RAG\n",
            "Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving external knowledge.\n",
            "\n",
            "Chunk 2:\n",
            "Benefits of RAG\n",
            "RAG improves accuracy and reduces hallucinations.\n",
            "\n",
            "Chunk 3:\n",
            "Applications\n",
            "Used in chatbots, search engines, and enterprise AI.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion & Takeaways**\n",
        "\n",
        "üìå Character Splitting ‚Üí Best for unstructured text, ensures fixed-length chunks.\n",
        "\n",
        "üìå HTML Header Splitting ‚Üí Best for structured documents, maintains section integrity.\n",
        "\n",
        "üìå Hybrid Splitting ‚Üí Combines both for optimal retrieval and generation in GenAI."
      ],
      "metadata": {
        "id": "lIzWymPB6XNR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GaqBvjN06ENM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}